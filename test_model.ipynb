{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from db_handler import DBHandler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2021-02-26 19:13:58,575 logging started\n",
      "INFO 2021-02-26 19:13:58,577 Setting up test table\n",
      "INFO 2021-02-26 19:13:58,857 Reading data from database: comp3208-train-small.csv\n"
     ]
    }
   ],
   "source": [
    "db = DBHandler()\n",
    "db.setup_test_table()\n",
    "\n",
    "R = {}\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "for x in db.read_data(\"comp3208-train-small.csv\"):\n",
    "    list_parts = x.strip().split(',')\n",
    "\n",
    "    if list_parts[2] == \"rating\":\n",
    "        continue\n",
    "    \n",
    "    user = int(list_parts[0]) - 1\n",
    "    item = int(list_parts[1]) - 1\n",
    "    rating = float(list_parts[2])\n",
    "        \n",
    "    if int(user) > row:\n",
    "        row = user\n",
    "    if item > col:\n",
    "        col = item\n",
    "    \n",
    "    if user in R:\n",
    "        R[user][item] = rating\n",
    "    else:\n",
    "        R[user] = {item: rating}\n",
    "        \n",
    "row += 1\n",
    "col += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2021-02-26 19:12:07,503 logging started\n",
      "INFO 2021-02-26 19:12:07,505 Setting up test table\n",
      "INFO 2021-02-26 19:12:08,015 Reading data from database: comp3208-train-small.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9425745\n"
     ]
    }
   ],
   "source": [
    "db = DBHandler()\n",
    "db.setup_test_table()\n",
    "\n",
    "row = [] # user\n",
    "col = [] # item\n",
    "rating = []\n",
    "\n",
    "for x in db.read_data(\"comp3208-train-small.csv\"):\n",
    "    line_split = x.strip().split(',')\n",
    "    if line_split[2] == \"rating\":\n",
    "        continue\n",
    "    row.append(int(line_split[0]) - 1)\n",
    "    col.append(int(line_split[1]) - 1)\n",
    "    rating.append(float(line_split[2]))\n",
    "    count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "R = coo_matrix((rating, (row, col)), shape=((max(row) + 1), (max(col) + 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Factor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def calc_mse(R, U, V, lamda=0.02):\n",
    "    ratings = R.data\n",
    "    rows = R.row\n",
    "    cols = R.col\n",
    "    total_error = 0\n",
    "    \n",
    "    for index in range(len(ratings)):\n",
    "        rating = ratings[index]\n",
    "        user = rows[index]\n",
    "        item = cols[index]\n",
    "        \n",
    "        # lambda for regularisation\n",
    "        if rating > 0:\n",
    "            total_error = total_error + pow(rating - np.dot(U[user,:], V[:,item]), 2) + lamda * (pow(norm(U[user,:]), 2) + pow(norm(V[:,item]), 2))\n",
    "    print(len(ratings))\n",
    "    \n",
    "    return total_error / len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(R, K, lam = 0.02, steps = 10, learning_rate = 0.01):\n",
    "    # using K create matricies U and V\n",
    "    M, N = R.shape\n",
    "    np.random.seed(0)\n",
    "    U = np.random.rand(M, K)\n",
    "    np.random.seed(1)\n",
    "    V = np.random.rand(K, N)\n",
    "    mse = calc_mse(R, U, V)\n",
    "    \n",
    "    for step in range(steps):\n",
    "        for index in range(len(R.data)):\n",
    "            # --> you can parallelise this\n",
    "            rating = R.data[index]\n",
    "            user = R.row[index]\n",
    "            item = R.col[index]\n",
    "            # ignore 0 ratings as its means that no rating has been made\n",
    "            if rating > 0:\n",
    "                loss = rating - np.dot(U[user,:], V[:,item])\n",
    "                U[user,:] = U[user,:] + learning_rate * 2 * (loss * V[:,item] - lam * U[user,:])\n",
    "                V[:,item] = V[:,item] + learning_rate * 2 * (loss * U[user,:] - lam * V[:,item])\n",
    "            # <-- end\n",
    "        mse = calc_mse(R, U, V)\n",
    "    print(\"Final MSE:\", mse)\n",
    "    \n",
    "    return U, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "# dict version\n",
    "def calc_mse(R, U, V, lamda=0.02):\n",
    "    total_error = 0\n",
    "    count = 0\n",
    "    \n",
    "    for user, ratings in R.items():\n",
    "        for item, rating in ratings.items():\n",
    "            total_error = total_error + pow(rating - np.dot(U[user,:], V[:,item]), 2) + lamda * (pow(norm(U[user,:]), 2) + pow(norm(V[:,item]), 2))\n",
    "            count += 1\n",
    "    \n",
    "    return total_error / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict version\n",
    "def gradient_descent(R, K, shape, lam = 0.02, steps = 10, learning_rate = 0.01):\n",
    "    # using K create matricies U and V\n",
    "    M, N = shape\n",
    "    np.random.seed(0)\n",
    "    U = np.random.rand(M, K)\n",
    "    np.random.seed(1)\n",
    "    V = np.random.rand(K, N)\n",
    "    # mse = calc_mse(R, U, V)\n",
    "    \n",
    "    for step in range(steps):\n",
    "        # split R into n chunks, aggregrate the U and V of all the processes\n",
    "        # --> you can parallelise this\n",
    "        for user, ratings in R.items():\n",
    "            for item, rating in ratings.items():\n",
    "                loss = rating - np.dot(U[user,:], V[:,item])\n",
    "                U[user,:] = U[user,:] + learning_rate * 2 * (loss * V[:,item] - lam * U[user,:])\n",
    "                V[:,item] = V[:,item] + learning_rate * 2 * (loss * U[user,:] - lam * V[:,item])\n",
    "        # <-- end\n",
    "    mse = calc_mse(R, U, V)\n",
    "    print(\"Final MSE:\", mse)\n",
    "    \n",
    "    return U, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MSE: 1.0490034627151001\n"
     ]
    }
   ],
   "source": [
    "U, V = gradient_descent(R, K=3, shape=(row, col), lam=0.01, steps=10, learning_rate=0.001) #shape=(row, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
